{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parallel-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import heapq, sys, copy, random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-nitrogen",
   "metadata": {},
   "source": [
    "# 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-contribution",
   "metadata": {},
   "source": [
    "Thompson sampling의 다양한 적용 방법에 대한 설명을 하기 위해서는 Bernoulli Bandit보다는 복잡한 예시가 필요하다. 그래서 각 edge를 통과하는 데 걸리는 시간이 확률적으로 정해지는 Binary Bridge에서 최단 거리 탐색 문제를 Thompson sampling을 비롯한 여러 online learning algorithm들을 통해 해결하는 과정을 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-greek",
   "metadata": {},
   "source": [
    "## Binary Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recovered-school",
   "metadata": {},
   "source": [
    "$s$에서 출발해 $d$에 도착하기까지 총 $n$(짝수)개의 stage가 있다고 할 때, 책에서 설명하는 Binary Bridge는 아래와 같은 방식으로 정의되는 그래프다.\n",
    "\n",
    "1. (node 배치) $i=0,\\ldots,n$에 대해 아래 과정을 반복한다.\n",
    "    1. $p=(i + 1) - 2\\text{max}(0, i - \\frac{n}{2})$개의 노드를 정의한다.\n",
    "    1. $p$개의 node를 각각 $(i, j)$에 배치시킨다$(j=0,\\ldots,p-1)$\n",
    "1. (node 연결) 임의의 노드 $(x,y)$에 대해 아래 과정을 반복한다.\n",
    "    1. $(x+1, y+1)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "    1. $(x+1, y)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "    1. $(x+1, y)$로 가는 edge가 정의되어 있지 않고, $(x+1, y-1)$이 정의되어 있으면 $(x,y)$에서 여기로 가는 방향을 가진 edge를 정의한다.\n",
    "1. $(0,0), (n,0)$을 각각 $s, d$로 설정한다.\n",
    "\n",
    "예를 들어, 6개의 stage를 갖는 Binary Bridge의 형태는 책의 `Figure 4.2`와 같은 형태를 갖는다. 참고로 책에서는 stage가 20개인 Binary Bridge를 생성해서 분석한다.\n",
    "\n",
    "<img src=\"images/binary_bridge.png\" alt=\"Binary Bridge example\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-lloyd",
   "metadata": {},
   "source": [
    "## Stochastic Travel Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-tourist",
   "metadata": {},
   "source": [
    "Agent는 각 stage마다 한 edge를 타고 이동한다. edge를 통과하는 데 걸리는 시간이 확률적이라는 말은 어떤 edge든 통과하는 데 걸리는 시간이 매 step마다 다르다는 것이다. 마치 경부고속도로의 길이는 항상 일정한데, 서울에서 부산까지 가는 데 걸리는 시간은 매번 다른 것과 같다. 이런 특징을 갖는 모의 시스템을 구현하기 위해서, 인접한 두 node $m, n$을 연결하는 edge마다 $t$번째 step에서 그 edge를 지나는 데 걸리는 시간 $y_{m,n,t}$를 매번 다르게 생성하는 확률분포가 필요하다. 이 확률분포는\n",
    "- 평균이 $\\theta_{m,n}$이고(즉, 이 edge를 지나는 데 걸리는 시간의 평균은 $\\theta_{m,n}$)\n",
    "- 양의 실수에 대해 정의된 분포여야 한다.\n",
    "\n",
    "책에서는 이를 아래와 같은 로그정규분포(Log Normal distribution)로 설정했다. $X$가 정규분포를 따르면 $Y=\\text{exp(X)}$는 로그정규분포를 따른다(즉, $\\ln Y$가 정규분포를 따름). 편의를 위해 아랫첨자를 모두 생략했다.\n",
    "$$\n",
    "y|\\theta\\sim LN(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}, \\widetilde{\\sigma}^2),\\;\\;\\theta\\sim LN(\\mu_0,\\sigma^2_0)\n",
    "$$\n",
    "\n",
    "- $\\mathbb{E}[y|\\theta]=\\theta$가 될 수 있도록 하기 위해 $y|\\theta$의 분포를 위와 같이 설정한 것이다(로그정규분포의 기대값 도출 증명은 하단의 appendix 참고). edge를 통과하는 데 걸리는 시간의 평균인 $\\theta$역시 로그정규분포를 따르도록 해 양의 실수값만을 갖도록 한다.\n",
    "- 두 분포에 포함된 $(\\widetilde{\\sigma}^2, \\mu_0, \\sigma^2_0)$는 값이 알려져 있다고 가정하는 초모수들이다. 참고로 이 예시에서는 $\\widetilde{\\sigma}^2, \\mu_0, \\sigma^2_0=(1, -0.5, 1)$로 설정했다.\n",
    "\n",
    "여기까지의 내용을 통해 요약에서 언급한 edge를 통과하는 데 걸리는 시간이 확률적으로 정해지는 Binary Bridge를 정의했다. 이를 아래와 같이 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absent-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryBridge:\n",
    "    \n",
    "    def __init__(self, n_stages, mu0, sig02):\n",
    "        \"\"\"\n",
    "        각 edge를 지나는 데 걸리는 시간의 평균을 로그정규분포에서 생성하는 Binary Bridge를 생성하고 그 최단경로를 저장하는 클래스\n",
    "        \"\"\"\n",
    "        assert (n_stages % 2 == 0), 'number of stages has to be even'\n",
    "        self.n = n_stages\n",
    "        self.mu0 = mu0\n",
    "        self.sig02 = sig02\n",
    "        \n",
    "        self.nodes = set()\n",
    "        self.graph = defaultdict(dict)\n",
    "        self.minimum_distance = None\n",
    "        self.shortest_path = None\n",
    "        \n",
    "        self._create_graph() # Binary Bridge를 생성하고,\n",
    "        self._apply_dijkstra() # s에서 d로 가는 데 지나가는 edge들에 대응하는 theta들의 합이 최소가 되는 경로를 shortest_path로 저장\n",
    "        \n",
    "    def _get_stage_width(self, x):\n",
    "        \"\"\"\n",
    "        수직선 x=p 위에 node들이 몇 개 정의되어야 하는지를 반환\n",
    "        \"\"\"\n",
    "        width = (x + 1) - 2 * max(0, x - self.n/2)\n",
    "        return int(width)\n",
    "    \n",
    "    def _generate_nodes(self):\n",
    "        \"\"\"\n",
    "        q = _get_stage_width(p)라고 하면, x=p위에 놓여야 할 q개의 node(들)을 순서쌍 형태로 정의해서 저장\n",
    "        \"\"\"\n",
    "        for x in range(self.n + 1):\n",
    "            for y in range(self._get_stage_width(x)):\n",
    "                self.nodes.add((x, y))\n",
    "        \n",
    "    def _generate_edges(self):\n",
    "        \"\"\"\n",
    "        위에서 생성한 node들을 기반으로, 정의될 수 있는 edge들 각각의 평균인 theta를 모수가 mu0, sig02인 로그정규분포에서 임의로 생성\n",
    "        \"\"\"\n",
    "        for x in range(self.n + 1):\n",
    "            for y in range(self._get_stage_width(x)):\n",
    "                current = (x, y)\n",
    "                up_shape = (x+1, y+1)\n",
    "                flat_shape = (x+1, y)\n",
    "                down_shape = (x+1, y-1)\n",
    "                \n",
    "                if up_shape in self.nodes:\n",
    "                    self.graph[current][up_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "                if flat_shape in self.nodes:\n",
    "                    self.graph[current][flat_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "                if down_shape in self.nodes and flat_shape not in self.nodes:\n",
    "                    self.graph[current][down_shape] = np.exp(np.random.normal(self.mu0, np.sqrt(self.sig02)))\n",
    "\n",
    "                \n",
    "    def _create_graph(self):\n",
    "        \"\"\"\n",
    "        위 method들을 기반으로 Binary Bridge를 생성\n",
    "        \"\"\"\n",
    "        self._generate_nodes()\n",
    "        self._generate_edges()\n",
    "        \n",
    "    def _apply_dijkstra(self):\n",
    "        \"\"\"\n",
    "        생성한 Binary Bridge에 대해 Dijkstra 알고리즘을 사용해 아래와 같은 정보를 획득\n",
    "         - self.shortest_path    : s에서 d까지 가는 데 지나게 되는 edge에 대응하는 theta들의 총합이 가장 작은 경로\n",
    "         - self.minimum_distance : 위 경로에 대응하는 theta들의 총합\n",
    "        \"\"\"\n",
    "        distances = dict([(node, np.inf) for node in self.nodes])\n",
    "        distances[(0,0)] = 0\n",
    "        prev_path = defaultdict(list)\n",
    "\n",
    "        to_visit = [[0, (0,0)]]\n",
    "        while to_visit:\n",
    "            distance, visiting = heapq.heappop(to_visit)\n",
    "            for destination in self.graph[visiting].keys():\n",
    "                new_distance = distance + self.graph[visiting][destination]\n",
    "                if new_distance < distances[destination]:\n",
    "                    distances[destination] = new_distance\n",
    "                    prev_path[destination] = prev_path[visiting] + [visiting]\n",
    "                    heapq.heappush(to_visit, [new_distance, destination])\n",
    "        \n",
    "        arrival = (self.n, 0)\n",
    "        self.shortest_path = prev_path[arrival] + [arrival]\n",
    "        self.minimum_distance = distances[arrival]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-tuner",
   "metadata": {},
   "source": [
    "경로에 포함된 edge들 각각에 해당하는 $\\theta$의 합이 가장 작은 경로가 최적의 경로라고 할 수 있다. 하지만 edge를 통과하는 데 걸리는 시간이 매번 다른 상황에서 이런 경로를 찾아내기 위해서는 $s$에서 $d$로 가는 경로들을 여러번 시도해볼 수 밖에 없다. 이 과정에서 측정한 소요시간들을 바탕으로 각 edge별로 통과 소요시간의 평균인 $\\theta$에 대한 믿음을 업데이트해야 한다. 따라서 이 문제는 아래와 같은 step을 반복하는 experiment를 실행해서 해결할 수 있고, 그렇기에 Thompson sampling을 비롯한 online learning algorithm들을 사용해서 해결할 수 있음을 알 수 있다.\n",
    "\n",
    "1. Agent는 $s$에서 $d$로 가는 한 경로를 선택한다.\n",
    "1. Environment는 그 경로에 포함된 edge들 각각의 확률분포에서 소요시간을 생성해 outcome을 반환한다.\n",
    "1. Agent는 edge별 소요시간을 바탕으로 edge별 소요시간 기대값에 대한 믿음을 업데이트한다.\n",
    "\n",
    "즉, 위에서 정의된 `BinaryBridge` 클래스를 상속시켜서 Environment를 구현하기 위해서는, Agent의 action(경로 선택)에 대한 outcome(edge별 소요시간)을 반환하는 method가 추가로 필요하다. 또한, Agent들도 개인적으로 `BinaryBridge`의 인스턴스를 정의해서, 여기에 $\\theta$에 대한 자신의 믿음을 저장하고 업데이트한다. 이렇게 업데이트 된 믿음을 바탕으로 $t$시점에 사용할 $\\theta$들의 추정치들을 생성하고, 이 추정치들을 바탕으로 $t$시점에 선택할 action을 정하는 method들이 추가로 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-dealing",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-paintball",
   "metadata": {},
   "source": [
    "요약하면, `BinaryBridge`를 상속하는 Environment를 정의하기 위해 아래와 같은 method들을 추가로 정의해야 한다.\n",
    "- `generate_outcome` : (Environment) 정의된 Binary Bridge의 경로에 포함된 edge들로부터 소요시간을 생성하는 method\n",
    "- `overwrite_edge_length` : (Agent) $t$번째 step의 $\\theta$ 추정치들을 생성해 이를 그래프의 edge들에 저장\n",
    "- `get_shortest_path` : (Agent) 저장된 $\\theta$ 추정치들의 합이 제일 짧은 경로를 찾아내 $t$번째 step의 action으로 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breeding-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(BinaryBridge):\n",
    "    \n",
    "    def generate_outcome(self, action, sig2_tilde):\n",
    "        \"\"\"\n",
    "        Agent가 선택한 action에 포함된 모든 edge에 대해:\n",
    "         1. 해당 edge에 대응하는 로그정규분포로부터 소요시간 y를 생성함\n",
    "         2. 이 edge가 m에서 n으로 향하는 edge였다면, m:{n:y}와 같은 dictionary 형태로 소요시간을 반환\n",
    "        \"\"\"\n",
    "        elapsed_times = defaultdict(dict)\n",
    "        for visiting, destination in zip(action, action[1:]): # edge마다\n",
    "            theta = self.graph[visiting][destination]\n",
    "            parameter_lognorm = np.log(theta) - sig2_tilde / 2\n",
    "            elapsed_time = np.exp(np.random.normal(parameter_lognorm, sig2_tilde)) # 소요시간(y) 생성\n",
    "            elapsed_times[visiting][destination] = elapsed_time\n",
    "\n",
    "        return elapsed_times\n",
    "    \n",
    "    def overwrite_edge_length(self, mean_estimates):\n",
    "        \"\"\"\n",
    "        m에서 n으로 가는 edge에 해당하는 theta들의 추정치를 m:{n:estimate}의 형태로 입력받고, estimate을 graph[m][n]에 저장\n",
    "        \"\"\"\n",
    "        for start_node in mean_estimates:\n",
    "            for end_node in mean_estimates[start_node]:\n",
    "                self.graph[start_node][end_node] = mean_estimates[start_node][end_node]\n",
    "                \n",
    "    def get_shortest_path(self):\n",
    "        \"\"\"\n",
    "        덮어씌워진 theta로 이루어진 새로운 graph로부터 최단경로를 찾아내 node에 해당하는 순서쌍들의 list로 반환\n",
    "        \"\"\"\n",
    "        self._apply_dijkstra()\n",
    "        return self.shortest_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-nutrition",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-respect",
   "metadata": {},
   "source": [
    "먼저 Epsilon Greedy 알고리즘을 채택하는 Agent를 정의한다. 이 알고리즘은 매 step마다 $\\epsilon$의 확률로 explore, $1-\\epsilon$의 확률로 exploit을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accepting-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedy:\n",
    "    \n",
    "    def __init__(self, n_stages, mu0, sig02, epsilon=0.0, sig2_tilde=1.):\n",
    "\n",
    "        assert (n_stages % 2 == 0), 'number of stages has to be even'\n",
    "        self.n = n_stages\n",
    "        self.mu0 = mu0\n",
    "        self.sig02 = sig02\n",
    "        self.sig2_tilde = sig2_tilde\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.internal_env = Environment(n_stages, mu0, sig02) # Agent가 개인적으로 생성한 Environment의 인스턴스\n",
    "        self.posterior_params = copy.deepcopy(self.internal_env.graph) # 각 edge에 해당하는 theta의 모수를 저장할 객체\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                self.posterior_params[visiting][destination] = (mu0, sig02) # 모든 theta의 모수를 (mu0, sig02)로 초기화\n",
    "    \n",
    "    def update_parameters(self, reward):\n",
    "        \"\"\"\n",
    "        action에 포함된 edge마다:\n",
    "         1. edge를 통과해서 획득한 reward에 -1을 곱해 해당 edge를 통과하는 데 실제로 걸린 시간 elapse_time를 구함\n",
    "         2. theta의 현재 mean, variance, elapse_time을 가지고 theta에 대한 믿음을 업데이트(appendix 참조)\n",
    "        \"\"\"\n",
    "        for visiting in reward:\n",
    "            for destination in reward[visiting]:\n",
    "                elapse_time = -reward[visiting][destination]\n",
    "                previous_mean, previous_var = self.posterior_params[visiting][destination]\n",
    "                \n",
    "                precision_theta = 1. / previous_var\n",
    "                precision_noise = 1. / self.sig2_tilde\n",
    "                updated_var = 1. / (precision_theta + precision_noise)\n",
    "                \n",
    "                updated_mean = precision_theta * previous_mean + precision_noise * (np.log(elapse_time) + self.sig2_tilde / 2)\n",
    "                updated_mean = updated_mean / (precision_theta + precision_noise)\n",
    "                \n",
    "                self.posterior_params[visiting][destination] = (updated_mean, updated_var)\n",
    "        \n",
    "    def _posterior_mean(self):\n",
    "        \"\"\"\n",
    "        theta별 확률분포의 모수들을 바탕으로 theta의 평균을 구해 반환\n",
    "        (모수가 m, s인 로그정규분포의 평균은 exp(m+s/2)임. appendix 참조)\n",
    "        \"\"\"\n",
    "        posterior_means = copy.deepcopy(self.posterior_params)\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                mean, var = self.posterior_params[visiting][destination]\n",
    "                posterior_means[visiting][destination] = np.exp(mean + var / 2)\n",
    "        \n",
    "        return posterior_means\n",
    "    \n",
    "    def _explore(self):\n",
    "        \"\"\"\n",
    "        s부터 d까지의 경로 중 하나를 랜덤하게 선택하는 method\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        start_node = (0,0)\n",
    "        while True:\n",
    "            path += [start_node]\n",
    "            if start_node == (self.n, 0):\n",
    "                break\n",
    "            start_node = random.choice(list(self.internal_env.graph[start_node].keys()))\n",
    "        return path\n",
    "    \n",
    "    def _exploit(self):\n",
    "        \"\"\"\n",
    "        theta별 평균을 edge별 theta의 추정치로 사용해 최단경로를 탐색해 반환\n",
    "        \"\"\"\n",
    "        posterior_means = self._posterior_mean()\n",
    "        self.internal_env.overwrite_edge_length(posterior_means)\n",
    "        return self.internal_env.get_shortest_path()\n",
    "    \n",
    "    def pick_action(self):\n",
    "        \"\"\"\n",
    "        epsilon의 확률로 explore를, 1-epsilon의 확률로 exploit을 통해 action을 선택\n",
    "        \"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            path = self._explore()\n",
    "        else:\n",
    "            path = self._exploit()\n",
    "        return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-poison",
   "metadata": {},
   "source": [
    "다음으로 Thompson sampling 알고리즘을 채택하는 Agent를 정의한다. 이 알고리즘은 매번 $\\theta$의 확률분포에서 랜덤샘플을 생성해서 $\\theta$의 추정치로 삼고, 이를 바탕으로 최단경로를 탐색해 반환한다. 이처럼 확률분포에서 발생하는 랜덤성을 통해 explore와 exploit을 자동으로 조절한다는 점에서, explore가 일어날 확률을 Agent가 임의로 정해야 하는 Epsilon Greedy 알고리즘과의 차이가 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reflected-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thompson(EpsilonGreedy):\n",
    "    \n",
    "    def _posterior_sample(self):\n",
    "        \"\"\"\n",
    "        theta별 확률분포에서 랜덤샘플을 생성해 반환\n",
    "        \"\"\"\n",
    "        posterior_samples = copy.deepcopy(self.posterior_params)\n",
    "        for visiting in self.posterior_params:\n",
    "            for destination in self.posterior_params[visiting]:\n",
    "                mean, var = self.posterior_params[visiting][destination]\n",
    "                posterior_samples[visiting][destination] = np.exp(np.random.normal(mean, var))\n",
    "        return posterior_samples\n",
    "        \n",
    "    def pick_action(self):\n",
    "        \"\"\"\n",
    "        생성한 랜덤샘플을 edge별 theta의 추정치로 사용해 최단경로를 탐색해 반환\n",
    "        \"\"\"\n",
    "        posterior_samples = self._posterior_sample()\n",
    "        self.internal_env.overwrite_edge_length(posterior_samples)\n",
    "        return self.internal_env.get_shortest_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-cleaner",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-tiffany",
   "metadata": {},
   "source": [
    "$t$번째 step에 agent가 선택한 action에 포함된 한 edge를 통과하는 데 실제로 걸린 시간 $y$에 음의 부호를 붙인 값을 그 edge를 선택한 reward로 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(response):\n",
    "    reward = defaultdict(dict)\n",
    "    for visiting in response:\n",
    "        for destination in response[visiting]:\n",
    "            reward[visiting][destination] = -response[visiting][destination]\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-washington",
   "metadata": {},
   "source": [
    "Agent가 선택한 action을 바탕으로 outcome을 반환하고 이를 reward로 바꿔 agent에게 전달해 action에 포함된 edge별 $\\theta$를 업데이트하는 step을 정의한다. Experiment는 이 step을 반복하기만 하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "skilled-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "\n",
    "    def __init__(self, agent, environment, n_steps, exp_id):\n",
    "        \"\"\"\n",
    "        agent       : predefined instance of EpsilonGreedy or Thompson class\n",
    "        environment : predefined instance of Environment class\n",
    "        n_steps     : number of steps in current experiment\n",
    "        exp_id      : id of current experiment\n",
    "        \"\"\"\n",
    "        self.agent = agent\n",
    "        self.environment = environment\n",
    "        self.optimal_reward = -environment.minimum_distance\n",
    "        self.n_steps = n_steps\n",
    "        self.exp_id = exp_id\n",
    "        self.result = []\n",
    "        self.data_dict = {}\n",
    "\n",
    "    def _step(self, step_index):\n",
    "        # pick action -> generate outcome -> observe reward of the action -> update belief accordingly\n",
    "        action = self.agent.pick_action()\n",
    "        response = self.environment.generate_outcome(action, self.agent.sig2_tilde)\n",
    "        self.agent.update_parameters(reward_function(response))\n",
    "\n",
    "        # calculate regret of current action\n",
    "        expected_reward = 0\n",
    "        for visiting, destination in zip(action, action[1:]):\n",
    "            expected_reward -= self.environment.graph[visiting][destination]\n",
    "        regret = self.optimal_reward - expected_reward\n",
    "\n",
    "        # Leave log\n",
    "        self.cum_regret += regret\n",
    "        self.data_dict = {'step': (step_index + 1), \n",
    "                          'regret': regret, \n",
    "                          'action': action, \n",
    "                          'experiment_id':self.exp_id}\n",
    "        self.result.append(self.data_dict)\n",
    "    \n",
    "    def run(self):\n",
    "        self.cum_regret = 0\n",
    "        for t in range(self.n_steps):\n",
    "            self._step(t)\n",
    "        self.result = pd.DataFrame(self.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-colorado",
   "metadata": {},
   "source": [
    "각 알고리즘의 성능을 아래와 같은 절차를 통해 확인한다.\n",
    "1. stage의 개수가 20인 Binary Bridge를 정의한다.\n",
    "1. 다음을 500번 반복한다(즉, Experiment를 500번 실행)\n",
    "    1. $\\epsilon$이 각각 $(0.0,0.01,0.05,0.1)$인 Epsilon Greedy알고리즘을 채택한 agent와 Thompson sampling을 채택한 agent를 정의한다.\n",
    "    1. 각 agent마다 step을 500번 반복한다(즉, 한 Experiment는 500번의 step으로 이루어져 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "immediate-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "n_stages = 20\n",
    "mu0 = -0.5\n",
    "sig02 = 1\n",
    "\n",
    "n_steps = 500\n",
    "n_experiment = 500\n",
    "environment = Environment(n_stages, mu0, sig02)\n",
    "agent_types = ['greedy-0.0', 'greedy-0.01', 'greedy-0.05', 'greedy-0.1', 'ts']\n",
    "\n",
    "for exp_id in range(1, n_experiment+1):\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(str(exp_id))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    np.random.seed(exp_id)\n",
    "    for agent_type in agent_types:\n",
    "        if agent_type[:6] == 'greedy':\n",
    "            agent = EpsilonGreedy(n_stages, mu0, sig02, epsilon=float(agent_type.split('-')[1]))\n",
    "        else:\n",
    "            agent = Thompson(n_stages, mu0, sig02)\n",
    "        experiment = Experiment(agent, environment, n_steps, exp_id)\n",
    "        experiment.run()\n",
    "        experiment.result.insert(experiment.result.shape[1], 'agent', agent_type)\n",
    "        results.append(experiment.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-heater",
   "metadata": {},
   "source": [
    "# Regret plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-instrumentation",
   "metadata": {},
   "source": [
    "각 agent가 step별로 취한 action의 regret의 평균을 구해서 그래프를 그린 결과를 제시했다.\n",
    "- Explore를 전혀 하지 않는 Greedy 알고리즘보다는 매 step마다 $\\epsilon$의 확률로 explore를 실시하는 Epsilon Greedy알고리즘의 regret이 더 낮은 값으로 수렴하는 것을 확인할 수 있다.\n",
    "- 하지만 어떤 Epsilon Greedy 알고리즘보다도 Thompson sampling의 regret이 더 낮은 값으로 수렴한 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "freelance-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_concat = pd.concat(results)\n",
    "plt_df = df_concat.groupby(['agent', 'step']).agg({'regret':np.mean}).reset_index()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for agent_type in agent_types:\n",
    "    data = plt_df.loc[plt_df['agent'] == agent_type]\n",
    "    ax.plot(data['step'], data['regret'], label=agent_type)\n",
    "\n",
    "ax.set_xlabel('step')\n",
    "ax.set_ylabel('regret')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-stewart",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-health",
   "metadata": {},
   "source": [
    "## 로그정규분포의 확률밀도함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-prospect",
   "metadata": {},
   "source": [
    "로그정규분포의 확률밀도함수를 도출하는 것은 $X\\sim N(\\mu,\\sigma^2)$일 때 $Y=\\text{exp}(X)$의 확률밀도함수를 도출하는 것이다. $f(x)=\\text{exp}(x)$가 단조증가함수이므로 아래와 같은 전개가 성립한다.\n",
    "$$\n",
    "P(Y\\leq y)=P(\\text{exp}(X)\\leq y)=P(X\\leq\\ln y)=F_X(\\ln y)\n",
    "$$\n",
    "\n",
    "누적분포함수와 확률밀도함수와의 관계를 이용해 아래와 같은 결론을 얻는다.\n",
    "$$\n",
    "p_Y(y)=\\frac{\\mathrm{d}}{\\mathrm{d}y}P(Y\\leq y)=\\frac{\\mathrm{d}}{\\mathrm{d}y}F_X(\\ln y)=\\frac{\\mathrm{d}x}{\\mathrm{d}y}\\frac{\\mathrm{d}}{\\mathrm{d}x}F_X(\\ln y)=\\frac{1}{y}f_X(\\ln y)\n",
    "$$\n",
    "\n",
    "따라서, $X\\sim N(\\mu,\\sigma^2)$일 때, $Y=\\text{exp}(X)$의 확률밀도함수는 아래와 같다.\n",
    "$$\n",
    "\\therefore p_Y(y)=\\frac{1}{y\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(\\ln y-\\mu)^2}{2\\sigma^2}\\right),\\;\\;y>0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-twist",
   "metadata": {},
   "source": [
    "## 로그정규분포의 기대값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-statistics",
   "metadata": {},
   "source": [
    "위와 같은 확률밀도함수를 갖는 확률변수 $Y$의 평균을 계산해본다. 참고로 $X=\\ln Y$라고 하면 $\\frac{\\mathrm{d}y}{\\mathrm{d}x}=\\text{exp}(x)$이다(즉, $\\mathrm{d}y=\\text{exp}(x)\\mathrm{d}x$)\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y]=\\int_0^\\infty\\frac{y}{y\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(\\ln y-\\mu)^2}{2\\sigma^2}\\right)\\mathrm{d}y=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}+x\\right)\\mathrm{d}x\n",
    "$$\n",
    "\n",
    "지수부 안을 정리하고, 평균과 분산이 각각 $(\\mu-\\sigma^2, \\sigma^2)$인 정규분포의 성질을 활용하면 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Y]=\\text{exp}\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\\int_{-\\infty}^\\infty\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\text{exp}\\left(-\\frac{(x-\\mu+\\sigma^2)^2}{2\\sigma^2}\\right)\\mathrm{d}x=\\text{exp}\\left(\\mu+\\frac{\\sigma^2}{2}\\right)\n",
    "$$\n",
    "\n",
    "이를 통해, 위 예시에서와 같이 평균과 분산이 각각 $(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}, \\widetilde{\\sigma}^2)$인 정규분포로부터 로그 정규분포를 도출하면 그 로그 정규분포의 평균은 $\\text{exp}\\left(\\ln\\theta-\\frac{\\widetilde{\\sigma}^2}{2}+\\frac{\\widetilde{\\sigma}^2}{2}\\right)=\\theta$가 됨을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-timothy",
   "metadata": {},
   "source": [
    "## $\\theta$에 대한 믿음 업데이트하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-bibliography",
   "metadata": {},
   "source": [
    "$t$번째 step에서 노드 $m$에서 노드 $n$으로 향하는 edge를 통과하는 데 걸린 시간이 $y_{m,n,t}$로 측정되었을 때, 이 값을 바탕으로 이 edge를 통과하는 데 걸리는 시간의 기대값인 $\\theta_{m,n}$에 대한 믿음을 업데이트할 수 있다. 즉, 위에서 정의한 $\\theta_{m,n}$와 $y_{m,n,t}|\\theta_{m,n}$의 분포를 바탕으로 $\\theta_{m,n}|y_{m,n,t}$의 분포를 도출한다(편의상 아랫첨자는 생략한다). 먼저, 베이즈 정리에 따라,\n",
    "\n",
    "$$\n",
    "p(\\theta|y)\\propto p(y|\\theta)p(\\theta)\\equiv\\ln p(\\theta|y)\\propto \\ln p(y|\\theta) + \\ln p(\\theta)\n",
    "$$\n",
    "\n",
    "인데, 위에서 정의한 바에 따르면\n",
    "\n",
    "$$\n",
    "\\ln p(y|\\theta)=-\\ln y-\\frac{1}{2}\\ln 2\\pi - \\frac{1}{2}\\ln\\widetilde{\\sigma}^2-\\frac{(\\ln y-\\ln\\theta+\\frac{\\widetilde{\\sigma}^2}{2})^2}{2\\widetilde{\\sigma}^2},\\;\\;\\ln p(\\theta)=-\\ln\\theta-\\frac{1}{2}\\ln 2\\pi-\\frac{1}{2}\\ln\\sigma^2_0-\\frac{(\\ln\\theta-\\mu_0)^2}{2\\sigma^2_0}\n",
    "$$\n",
    "\n",
    "이므로, $\\ln p(y|\\theta) + \\ln p(\\theta)$를 $\\theta$에 대해 정리해서 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\ln p(\\theta|y)\\propto -\\ln\\theta-\\frac{(\\ln\\theta-\\mu_0)^2}{2\\sigma^2_0}-\\frac{\\left(\\ln y-\\ln\\theta+\\frac{\\widetilde{\\sigma}^2}{2}\\right)^2}{2\\widetilde{\\sigma}^2}\\;\\;\\cdots\\;\\;(1)\n",
    "$$\n",
    "\n",
    "이를 로그정규분포의 커널 형태에 맞게 정리할 수 있다. 즉,\n",
    "\n",
    "$$\n",
    "(1) \\propto -\\ln\\theta-\\left\\{\\frac{\\{(\\ln\\theta)^2-2\\mu_0\\ln\\theta+\\mu^2_0\\}}{2\\sigma^2_0}+\\frac{(\\ln\\theta)^2-2\\left(\\ln y+\\frac{\\widetilde{\\sigma}^2}{2}\\right)\\ln\\theta+\\left(\\ln y+\\frac{\\widetilde{\\sigma}^2}{2}\\right)^2}{2\\widetilde{\\sigma}^2}\\right\\}\\;\\;\\cdots\\;\\;(2)\n",
    "$$\n",
    "\n",
    "(2)를 $\\theta$에 대해 더 정리하면,\n",
    "\n",
    "$$\n",
    "(2)\\propto-\\ln\\theta-\\left\\{\\frac{1}{2}\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)(\\ln\\theta)^2-\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)\\ln\\theta\\right\\}\\propto-\\ln\\theta-\\frac{\\left\\{\\ln\\theta-\\frac{\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)}\\right\\}^2}{2\\left(1/\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)\\right)}\n",
    "$$\n",
    "\n",
    "이므로, 아래와 같은 결론을 얻는다.\n",
    "\n",
    "$$\n",
    "\\theta|y\\sim LN\\left(\\frac{\\left(\\frac{\\mu_0}{\\sigma^2_0}+\\frac{\\ln y}{\\widetilde{\\sigma}^2}+\\frac{1}{2}\\right)}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)},\\frac{1}{\\left(\\frac{1}{\\sigma^2_0}+\\frac{1}{\\widetilde{\\sigma}^2}\\right)}\\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
